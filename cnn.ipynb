{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 21.4](images/fig_21_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_w = [[[1., -1., 1.]]] # out_channels: 1, in_channels: 1, kernel_size: 3\n",
    "conv_b = [0.] # out_channels: 1\n",
    "in_arr = [[[5., 6., 6., 2., 5., 6., 5.]]] # batch size: 1, num channel: 1, signal length: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 22:18:32.353946: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-09 22:18:32.356219: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 22:18:32.389722: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 22:18:32.390461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 22:18:32.879330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_w_t = torch.Tensor(conv_w)\n",
    "conv_b_t = torch.Tensor(conv_b)\n",
    "in_t = torch.Tensor(in_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The implementation in PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method \\#1: Using the graph building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Parameter containing:\n",
      "tensor([[[ 1., -1.,  1.]]], requires_grad=True) \n",
      "\n",
      "bias Parameter containing:\n",
      "tensor([0.], requires_grad=True) \n",
      "\n",
      "Output:  tensor([[[5., 9., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the 1-D convolution module\n",
    "conv = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2)\n",
    "# assign the weights to match Figure 21.4\n",
    "for name, param in conv.named_parameters():\n",
    "    if name == \"weight\":\n",
    "        param.data = torch.nn.parameter.Parameter(conv_w_t)\n",
    "    elif name == \"bias\":\n",
    "        param.data = torch.nn.parameter.Parameter(conv_b_t)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    print(name, param, \"\\n\")\n",
    "# forward-pass the input\n",
    "with torch.no_grad():\n",
    "    out_t = conv(in_t)\n",
    "print(\"Output: \", out_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method \\#2: Using the functional interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[[5., 9., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "# do 1-D convolution on the input\n",
    "# the weights of the 1-D convolution function is matched to Figure 21.4\n",
    "with torch.no_grad():\n",
    "    out_t = torch.nn.functional.conv1d(input=in_t, weight=conv_w_t, bias=conv_b_t, stride=2)\n",
    "print(\"Output: \", out_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 22:18:35.453604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 22:18:35.453778: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# by default, TF operations assume the tensors are channel-last\n",
    "# so, we transpose our input from (batch size, num channel, signal length) to (batch size, signal length, num channel)\n",
    "in_t = tf.transpose(tf.constant(in_arr), [0, 2, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The implementation in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight and bias:  [array([[[ 1.]],\n",
      "\n",
      "       [[-1.]],\n",
      "\n",
      "       [[ 1.]]], dtype=float32), array([0.], dtype=float32)] \n",
      "\n",
      "Output:  tf.Tensor(\n",
      "[[[5.]\n",
      "  [9.]\n",
      "  [4.]]], shape=(1, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the 1-D convolution module\n",
    "conv = tf.keras.layers.Conv1D(filters=1, kernel_size=3, strides=2, input_shape=(None, 1))\n",
    "_ = conv(in_t)  # initialize the weights before setting the weights\n",
    "# assign the weights to match Figure 21.4\n",
    "conv.set_weights([\n",
    "    np.array(conv_w).T,  # need to transpose because of the channel-last in TF operations\n",
    "    np.array(conv_b)\n",
    "])\n",
    "print(\"weight and bias: \", conv.get_weights(), \"\\n\")\n",
    "# forward-pass the input\n",
    "outputs = conv(in_t)\n",
    "print(\"Output: \", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ai_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45806f2a31fc2394908bf2aae38bc8f96498b1e9c39d8308e884e6256764b6c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
